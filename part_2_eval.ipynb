{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './xray_dataset/'\n",
    "# convert all input images to square tensors\n",
    "# this step is probably ruining the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((256, 256)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4),\n",
    "    transforms.ColorJitter(brightness=0.3),\n",
    "    transforms.RandomRotation(15),\n",
    "    # normalize the data\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "# Load training data\n",
    "train_data = ImageFolder(root=data_dir + 'train', transform=transform)\n",
    "\n",
    "# Load validation data\n",
    "val_data = ImageFolder(root=data_dir + 'val', transform=transform)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=True)\n",
    "\n",
    "# Load test data\n",
    "test_data = ImageFolder(root=data_dir + 'test', transform=transform)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from CNN import *\n",
    "from captum.attr import IntegratedGradients\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, accuracy_score\n",
    "\n",
    "# Define paths and constants\n",
    "MODEL_PATH = './xray_net.pth'\n",
    "DEVICE = 'cuda'\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# Load the model and test data\n",
    "model = CNN().to(DEVICE)\n",
    "model.load_state_dict(torch.load(\n",
    "    MODEL_PATH, map_location=torch.device(DEVICE)))\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=1, shuffle=False, num_workers=1, pin_memory=True)\n",
    "\n",
    "# Generate predictions and labels for the test data\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "for images, labels in tqdm(test_loader):\n",
    "    images = images.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)\n",
    "\n",
    "    # Generate a prediction for the current sample\n",
    "    with torch.no_grad():\n",
    "        output = model(images)\n",
    "    predictions = torch.argmax(output, dim=1)\n",
    "\n",
    "    all_predictions.append(predictions.item())\n",
    "    all_labels.append(labels.item())\n",
    "\n",
    "# Calculate the recall and accuracy scores\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "\n",
    "f1 = f1_score(all_labels, all_predictions)\n",
    "\n",
    "# Print the recall and accuracy scores\n",
    "print('Recall:', recall)\n",
    "print('Accuracy:', accuracy)\n",
    "print('F1:', f1)\n",
    "\n",
    "# Generate and plot the confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "plt.matshow(cm, cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from CNN import *\n",
    "\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from PIL import Image\n",
    "\n",
    "# Move the model and test data to the GPU\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cuda'\n",
    "model = CNN().to(device)\n",
    "model.load_state_dict(torch.load(\n",
    "    MODEL_PATH, map_location=torch.device(device)))\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=1, shuffle=False, num_workers=1, pin_memory=True)\n",
    "\n",
    "# Define the Integrated Gradients explainer\n",
    "ig = IntegratedGradients(model.to(device))\n",
    "\n",
    "# Define a helper function to display the attribution map on the original image\n",
    "\n",
    "\n",
    "def visualize_attribution(original_image, attribution_map):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 10))\n",
    "    ax1.imshow(original_image)\n",
    "    ax1.axis('off')\n",
    "    ax2.imshow(attribution_map, cmap='gray')\n",
    "    ax2.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Generate attribution maps for 5 healthy and 5 pneumonia test samples\n",
    "healthy_count = 0\n",
    "pneumonia_count = 0\n",
    "for images, labels in test_loader:\n",
    "    # Skip samples until we have 5 of each class\n",
    "    if healthy_count == 5 and pneumonia_count == 5:\n",
    "        break\n",
    "\n",
    "    if labels == 0 and healthy_count == 5:\n",
    "        # print('Skipping healthy sample')\n",
    "        continue\n",
    "\n",
    "    if labels == 1 and pneumonia_count == 5:\n",
    "        # print('Skipping unhealthy sample')\n",
    "        continue\n",
    "\n",
    "    # Move images and labels to the GPU\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # print(images.shape, labels.shape)\n",
    "    print(\"Predictions:\", torch.argmax(model(images)))\n",
    "\n",
    "    # Generate an attribution map for the current sample\n",
    "    images.requires_grad = True\n",
    "    attribution = ig.attribute(images, target=labels)\n",
    "    print(attribution.shape, images.shape)\n",
    "\n",
    "    attribution_map = np.transpose(\n",
    "        attribution.squeeze().cpu().detach().numpy())\n",
    "    # break\n",
    "\n",
    "    attribution *= 1000\n",
    "    # print(attribution_map)\n",
    "\n",
    "    # print(attribution_map)\n",
    "    # normalize attribution map\n",
    "    # attribution_map = (attribution_map - np.min(attribution_map)) / \\\n",
    "    #     (np.max(attribution_map) - np.min(attribution_map)) * 255\n",
    "\n",
    "    # print(attribution_map)\n",
    "\n",
    "    # break\n",
    "\n",
    "    # Display the attribution map on the original image\n",
    "    if labels == 0 and healthy_count < 5:\n",
    "        print('Healthy sample:', healthy_count+1)\n",
    "        visualize_attribution(np.transpose(\n",
    "            images.squeeze().cpu().detach().numpy()), attribution_map)\n",
    "        healthy_count += 1\n",
    "    elif labels == 1 and pneumonia_count < 5:\n",
    "        print('Pneumonia sample:', pneumonia_count+1)\n",
    "        visualize_attribution(np.transpose(\n",
    "            images.squeeze().cpu().detach().numpy()), attribution_map)\n",
    "        pneumonia_count += 1\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
